{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad43438",
   "metadata": {},
   "source": [
    "## 📊 数据集准备\n",
    "\n",
    "仅需要以以下文件结构将数据集放入 dataset_raw 目录即可。\n",
    "\n",
    "```\n",
    "dataset_raw\n",
    "├───speaker0\n",
    "│   ├───xxx1-xxx1.wav\n",
    "│   ├───...\n",
    "│   └───Lxx-0xx8.wav\n",
    "└───speaker1\n",
    "    ├───xx2-0xxx2.wav\n",
    "    ├───...\n",
    "    └───xxx7-xxx007.wav\n",
    "```\n",
    "对于每一个音频文件的名称并没有格式的限制(`000001.wav`~`999999.wav`之类的命名方式也是合法的)，不过文件类型必须是`wav`。\n",
    "\n",
    "可以自定义说话人名称\n",
    "\n",
    "```\n",
    "dataset_raw\n",
    "└───suijiSUI\n",
    "    ├───1.wav\n",
    "    ├───...\n",
    "    └───25788785-20221210-200143-856_01_(Vocals)_0_0.wav\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356bde80",
   "metadata": {},
   "source": [
    "## 🛠️ 数据预处理\n",
    "\n",
    "### 0. 音频切片\n",
    "\n",
    "将音频切片至`5s - 15s`, 稍微长点也无伤大雅，实在太长可能会导致训练中途甚至预处理就爆显存\n",
    "\n",
    "可以使用 [audio-slicer-GUI](https://github.com/flutydeer/audio-slicer)、[audio-slicer-CLI](https://github.com/openvpi/audio-slicer)\n",
    "\n",
    "一般情况下只需调整其中的`Minimum Interval`，普通陈述素材通常保持默认即可，歌唱素材可以调整至`100`甚至`50`\n",
    "\n",
    "切完之后手动删除过长过短的音频"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919ac7df",
   "metadata": {},
   "source": [
    "### 1. 重采样至 44100Hz 单声道\n",
    "\n",
    "```shell\n",
    "python resample.py\n",
    "```\n",
    "#### 注意\n",
    "\n",
    "虽然本项目拥有重采样、转换单声道与响度匹配的脚本 resample.py，但是默认的响度匹配是匹配到 0db。这可能会造成音质的受损。而 python 的响度匹配包 pyloudnorm 无法对电平进行压限，这会导致爆音。所以建议可以考虑使用专业声音处理软件如`adobe audition`等软件做响度匹配处理。若已经使用其他软件做响度匹配，可以在运行上述命令时添加`--skip_loudnorm`跳过响度匹配步骤。如：\n",
    "\n",
    "```shell\n",
    "python resample.py --skip_loudnorm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b66936",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python resample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca615343",
   "metadata": {},
   "source": [
    "### 2. 自动划分训练集、验证集，以及自动生成配置文件\n",
    "\n",
    "```shell\n",
    "python preprocess_flist_config.py --speech_encoder vec768l12\n",
    "```\n",
    "\n",
    "speech_encoder 拥有以下选择\n",
    "\n",
    "```\n",
    "vec768l12\n",
    "vec256l9\n",
    "hubertsoft\n",
    "whisper-ppg\n",
    "whisper-ppg-large\n",
    "cnhubertlarge\n",
    "dphubert\n",
    "wavlmbase+\n",
    "```\n",
    "\n",
    "如果省略 speech_encoder 参数，默认值为 vec768l12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_flist_config.py --speech_encoder vec768l12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22759624",
   "metadata": {},
   "source": [
    "#### 此时可以在生成的 config.json 与 diffusion.yaml 修改部分参数\n",
    "\n",
    "##### config.json\n",
    "\n",
    "* `keep_ckpts`：训练时保留最后几个模型，`0`为保留所有，默认只保留最后`3`个\n",
    "\n",
    "* `all_in_mem`：加载所有数据集到内存中，某些平台的硬盘 IO 过于低下、同时内存容量 **远大于** 数据集体积时可以启用\n",
    "\n",
    "* `batch_size`：单次训练加载到 GPU 的数据量，调整到低于显存容量的大小即可\n",
    "\n",
    "* `vocoder_name` : 选择一种声码器，默认为`nsf-hifigan`.\n",
    "\n",
    "##### diffusion.yaml\n",
    "\n",
    "* `cache_all_data`：加载所有数据集到内存中，某些平台的硬盘 IO 过于低下、同时内存容量 **远大于** 数据集体积时可以启用\n",
    "\n",
    "* `duration`：训练时音频切片时长，可根据显存大小调整，**注意，该值必须小于训练集内音频的最短时间！**\n",
    "\n",
    "* `batch_size`：单次训练加载到 GPU 的数据量，调整到低于显存容量的大小即可\n",
    "\n",
    "* `timesteps` : 扩散模型总步数，默认为 1000.\n",
    "\n",
    "* `k_step_max` : 训练时可仅训练`k_step_max`步扩散以节约训练时间，注意，该值必须小于`timesteps`，0 为训练整个扩散模型，**注意，如果不训练整个扩散模型将无法使用仅扩散模型推理！**\n",
    "\n",
    "##### **声码器列表**\n",
    "\n",
    "```\n",
    "nsf-hifigan\n",
    "nsf-snake-hifigan\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3a83e",
   "metadata": {},
   "source": [
    "### 3. 生成 hubert 与 f0\n",
    "\n",
    "```shell\n",
    "python preprocess_hubert_f0.py --f0_predictor dio\n",
    "```\n",
    "\n",
    "f0_predictor 拥有以下选择\n",
    "\n",
    "```\n",
    "crepe\n",
    "dio\n",
    "pm\n",
    "harvest\n",
    "rmvpe\n",
    "fcpe\n",
    "```\n",
    "\n",
    "如果训练集过于嘈杂，请使用 crepe 处理 f0\n",
    "\n",
    "如果省略 f0_predictor 参数，默认值为 dio\n",
    "\n",
    "尚若需要浅扩散功能（可选），需要增加--use_diff 参数，比如\n",
    "\n",
    "```shell\n",
    "python preprocess_hubert_f0.py --f0_predictor dio --use_diff\n",
    "```\n",
    "**加速预处理**\n",
    "如若您的数据集比较大，可以尝试添加`--num_processes`参数：\n",
    "```shell\n",
    "python preprocess_hubert_f0.py --f0_predictor dio --use_diff --num_processes 8\n",
    "```\n",
    "所有的Workers会被自动分配到多个线程上\n",
    "\n",
    "执行完以上步骤后 dataset 目录便是预处理完成的数据，可以删除 dataset_raw 文件夹了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d55d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_hubert_f0.py --f0_predictor dio --use_diff --num_processes 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05f4d3",
   "metadata": {},
   "source": [
    "## 🏋️‍ 训练\n",
    "\n",
    "### 主模型训练\n",
    "\n",
    "```shell\n",
    "python train.py -c configs/config.json -m 44k\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -c configs/config.json -m 44k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386c8d3",
   "metadata": {},
   "source": [
    "### 扩散模型（可选）\n",
    "\n",
    "尚若需要浅扩散功能，需要训练扩散模型，扩散模型训练方法为：\n",
    "\n",
    "```shell\n",
    "python train_diff.py -c configs/diffusion.yaml\n",
    "```\n",
    "\n",
    "模型训练结束后，模型文件保存在`logs/44k`目录下，扩散模型在`logs/44k/diffusion`下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d011c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_diff.py -c configs/diffusion.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7becfc1",
   "metadata": {},
   "source": [
    "## 🤖 推理\n",
    "\n",
    "使用 [inference_main.py](inference_main.py)\n",
    "\n",
    "```shell\n",
    "# 例\n",
    "python inference_main.py -m \"logs/44k/G_30400.pth\" -c \"configs/config.json\" -n \"君の知らない物語-src.wav\" -t 0 -s \"nen\"\n",
    "```\n",
    "\n",
    "必填项部分：\n",
    "+ `-m` | `--model_path`：模型路径\n",
    "+ `-c` | `--config_path`：配置文件路径\n",
    "+ `-n` | `--clean_names`：wav 文件名列表，放在 raw 文件夹下\n",
    "+ `-t` | `--trans`：音高调整，支持正负（半音）\n",
    "+ `-s` | `--spk_list`：合成目标说话人名称\n",
    "+ `-cl` | `--clip`：音频强制切片，默认 0 为自动切片，单位为秒/s\n",
    "\n",
    "可选项部分：部分具体见下一节\n",
    "+ `-lg` | `--linear_gradient`：两段音频切片的交叉淡入长度，如果强制切片后出现人声不连贯可调整该数值，如果连贯建议采用默认值 0，单位为秒\n",
    "+ `-f0p` | `--f0_predictor`：选择 F0 预测器，可选择 crepe,pm,dio,harvest,rmvpe,fcpe, 默认为 pm（注意：crepe 为原 F0 使用均值滤波器）\n",
    "+ `-a` | `--auto_predict_f0`：语音转换自动预测音高，转换歌声时不要打开这个会严重跑调\n",
    "+ `-cm` | `--cluster_model_path`：聚类模型或特征检索索引路径，留空则自动设为各方案模型的默认路径，如果没有训练聚类或特征检索则随便填\n",
    "+ `-cr` | `--cluster_infer_ratio`：聚类方案或特征检索占比，范围 0-1，若没有训练聚类模型或特征检索则默认 0 即可\n",
    "+ `-eh` | `--enhance`：是否使用 NSF_HIFIGAN 增强器，该选项对部分训练集少的模型有一定的音质增强效果，但是对训练好的模型有反面效果，默认关闭\n",
    "+ `-shd` | `--shallow_diffusion`：是否使用浅层扩散，使用后可解决一部分电音问题，默认关闭，该选项打开时，NSF_HIFIGAN 增强器将会被禁止\n",
    "+ `-usm` | `--use_spk_mix`：是否使用角色融合/动态声线融合\n",
    "+ `-lea` | `--loudness_envelope_adjustment`：输入源响度包络替换输出响度包络融合比例，越靠近 1 越使用输出响度包络\n",
    "+ `-fr` | `--feature_retrieval`：是否使用特征检索，如果使用聚类模型将被禁用，且 cm 与 cr 参数将会变成特征检索的索引路径与混合比例\n",
    "\n",
    "浅扩散设置：\n",
    "+ `-dm` | `--diffusion_model_path`：扩散模型路径\n",
    "+ `-dc` | `--diffusion_config_path`：扩散模型配置文件路径\n",
    "+ `-ks` | `--k_step`：扩散步数，越大越接近扩散模型的结果，默认 100\n",
    "+ `-od` | `--only_diffusion`：纯扩散模式，该模式不会加载 sovits 模型，以扩散模型推理\n",
    "+ `-se` | `--second_encoding`：二次编码，浅扩散前会对原始音频进行二次编码，玄学选项，有时候效果好，有时候效果差\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference_main.py -m \"logs/44k/G_30400.pth\" -c \"configs/config.json\" -n \"君の知らない物語-src.wav\" -t 0 -s \"nen\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svc",
   "language": "python",
   "name": "svc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
